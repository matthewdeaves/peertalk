name: PeerTalk CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  # POSIX build and tests (runs on every push/PR)
  build-posix:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: sudo apt-get update && sudo apt-get install -y gcc make lcov bc

      - name: Build POSIX
        run: |
          if [ -f "Makefile" ]; then
            make
          else
            echo "No Makefile yet - skipping POSIX build"
          fi

      - name: Run tests
        run: |
          if [ -f "Makefile" ]; then
            make test || exit 1
            echo "âœ“ All tests passed"
          else
            echo "No Makefile yet - skipping tests"
          fi

      - name: Check coverage
        run: |
          if [ -f "Makefile" ]; then
            make coverage
            COVERAGE=$(lcov --summary build/coverage/coverage.info 2>&1 | grep "lines" | awk '{print $2}' | tr -d '%')
            echo "Coverage: ${COVERAGE}%"
            if (( $(echo "$COVERAGE < 10.0" | bc -l) )); then
              echo "::warning::Coverage ${COVERAGE}% is below 10% threshold"
            fi
          else
            echo "No Makefile yet - skipping coverage"
          fi

  # ISR safety validation
  validate-isr-safety:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install validator dependencies
        run: pip install click rich

      - name: Run ISR Safety Validator
        run: |
          if [ -d "src/" ]; then
            python tools/validators/isr_safety.py src/
          else
            echo "No src/ directory yet - skipping ISR validation"
          fi

  # Retro68 cross-compilation - builds PeerTalk SDK library for Classic Mac platforms
  build-retro68:
    runs-on: ubuntu-latest
    # Only run on main branch or when Docker/Mac code changes
    if: github.ref == 'refs/heads/main' || contains(github.event.pull_request.labels.*.name, 'build-retro68')
    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          push: false
          load: true
          tags: peertalk-dev:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build PeerTalk SDK for 68k (MacTCP)
        run: |
          if [ -f "Makefile.retro68" ]; then
            docker run --rm -v ${{ github.workspace }}:/workspace peertalk-dev:latest \
              make -f Makefile.retro68 PLATFORM=mactcp
          else
            echo "No Makefile.retro68 yet - skipping SDK build for 68k"
          fi

      - name: Build PeerTalk SDK for PPC (Open Transport)
        run: |
          if [ -f "Makefile.retro68" ]; then
            docker run --rm -v ${{ github.workspace }}:/workspace peertalk-dev:latest \
              make -f Makefile.retro68 PLATFORM=ot
          else
            echo "No Makefile.retro68 yet - skipping SDK build for PPC"
          fi

  # Code quality gates
  quality-gates:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Check file sizes
        run: |
          echo "Checking file sizes (max 500 lines)..."
          ERRORS=0
          for f in $(find . \( -name "*.c" -o -name "*.h" \) | grep -v node_modules); do
            lines=$(wc -l < "$f")
            if [ "$lines" -gt 500 ]; then
              echo "::warning file=$f::$f has $lines lines (max 500)"
              ERRORS=$((ERRORS + 1))
            fi
          done
          if [ $ERRORS -gt 0 ]; then
            echo "::warning::$ERRORS files exceed 500 line limit"
          fi

      - name: Check for TODO/FIXME
        run: |
          echo "Checking for unresolved TODOs..."
          if grep -rn "TODO\|FIXME" --include="*.c" --include="*.h" . 2>/dev/null; then
            echo "::notice::Found TODO/FIXME comments - consider resolving"
          fi

  # Collect metrics and update dashboard
  collect-metrics:
    runs-on: ubuntu-latest
    needs: [build-posix, validate-isr-safety, quality-gates]
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/main'
    permissions:
      contents: write  # Needed to push to gh-pages

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for gh-pages

      - name: Install dependencies
        run: sudo apt-get update && sudo apt-get install -y python3 jq bc gcc make lcov pmccabe

      - name: Build library
        id: build
        run: |
          START_TIME=$(date +%s)
          make all 2>&1 | tee /tmp/build_output.txt
          BUILD_END=$(date +%s)
          echo "build_duration=$((BUILD_END - START_TIME))" >> $GITHUB_OUTPUT

      - name: Run tests
        id: tests
        run: |
          START_TIME=$(date +%s)
          make test 2>&1 | tee /tmp/test_output.txt
          TEST_END=$(date +%s)
          echo "test_duration=$((TEST_END - START_TIME))" >> $GITHUB_OUTPUT

      - name: Generate coverage
        id: coverage
        run: |
          START_TIME=$(date +%s)
          make coverage
          COV_END=$(date +%s)
          echo "coverage_duration=$((COV_END - START_TIME))" >> $GITHUB_OUTPUT

      - name: Extract metrics
        run: |
          mkdir -p /tmp/metrics

          # Extract test results
          ./tools/metrics/extract_test_results.sh /tmp/test_output.txt > /tmp/metrics/test_results.json

          # Extract test count metrics
          ./tools/metrics/extract_test_count.sh /tmp/test_output.txt > /tmp/metrics/test_count.json

          # Extract coverage metrics
          ./tools/metrics/extract_coverage.sh > /tmp/metrics/coverage.json

          # Extract ISR safety metrics
          ./tools/metrics/extract_isr_violations.sh > /tmp/metrics/isr_safety.json

          # Extract quality metrics
          ./tools/metrics/extract_quality_metrics.sh > /tmp/metrics/quality.json

          # Extract binary size metrics
          ./tools/metrics/extract_binary_size.sh > /tmp/metrics/binary_size.json

          # Extract complexity metrics
          ./tools/metrics/extract_complexity.sh > /tmp/metrics/complexity.json

          # Extract CI metrics (with timing from previous steps)
          export BUILD_DURATION_SEC="${{ steps.build.outputs.build_duration }}"
          export TEST_DURATION_SEC="${{ steps.tests.outputs.test_duration }}"
          export COVERAGE_DURATION_SEC="${{ steps.coverage.outputs.coverage_duration }}"
          ./tools/metrics/extract_ci_metrics.sh > /tmp/metrics/ci_metrics.json

      - name: Aggregate metrics
        run: |
          python3 tools/metrics/aggregate_metrics.py \
            /tmp/metrics/test_results.json \
            /tmp/metrics/coverage.json \
            /tmp/metrics/isr_safety.json \
            /tmp/metrics/quality.json \
            /tmp/metrics/ci_metrics.json \
            /tmp/metrics/aggregated.json \
            /tmp/metrics/binary_size.json \
            /tmp/metrics/complexity.json \
            /tmp/metrics/test_count.json

          echo "Aggregated metrics:"
          cat /tmp/metrics/aggregated.json | python3 -m json.tool

      - name: Generate HTML reports
        run: |
          # Generate ISR safety HTML report
          python3 tools/metrics/generate_isr_report.py \
            /tmp/metrics/isr_safety.json \
            /tmp/metrics/isr_report.html

      - name: Upload to gh-pages
        run: |
          ./tools/metrics/upload_to_pages.sh /tmp/metrics/aggregated.json build/coverage/html /tmp/metrics/isr_report.html
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
